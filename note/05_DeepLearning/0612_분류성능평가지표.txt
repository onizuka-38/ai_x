       예측0   예측1
실제0  TN      FP
실제1  FN      TP

※ accuracy(정확도) = (TN+TP)/(TN+FP+FN+TP)
※ precision(정밀도) = TP / (FP+TP) - 예측값기준
※ recall(재현율) = TP / (FN+TP) - 실제값 기준
※ f1 score = recall과 precision의 조화평균
       precision*recall
   2* ───────
       presision+recall

- Precision ↑ → Recall ↓  
- Recall ↑ → Precision ↓

- precisin을 높이려면 확실한 것만 Positive로 예측
- recall을 높이려면 조금이라도 가능성이 있으면 Positive로 예측

--------------
(1) 정확도(Accuracy)
전체에서 정답 맞춘 비율

(TN + TP) / 전체

예시: 100개 중 90개 맞추면 90%

장점:

전체적으로 얼마나 잘 맞췄는지 한눈에 알 수 있음

단점:

클래스 불균형(예: 암환자 1명, 정상 99명)에서는 의미가 퇴색됨

---------------------------
(2) 정밀도(Precision)
내가 1(Positive)라고 예측한 것 중 진짜 1(Positive)이 얼마나 되는가?
TP / (FP + TP)

예시: 암 진단에서 "암입니다"라고 예측한 10명 중 실제 암환자가 7명이면, 정밀도는 70%

활용 예시:

스팸 필터: "스팸!"이라고 한 메일 중에 진짜 스팸만 골라내고 싶을 때

즉, 잘못(거짓) 양성을 줄이고 싶을 때!

---------------------
(3) 재현율(Recall)
실제로 1(Positive)인 것 중에 내가 얼마나 잘 1(Positive)라고 예측했나?
TP / (FN + TP)

예시: 실제 암환자 10명 중 8명을 "암입니다"라고 맞히면, 재현율은 80%

활용 예시:

암 진단: 암환자를 한 명도 놓치면 안 될 때

즉, 놓치지 않고(거짓 음성 줄이기) 최대한 많이 잡고 싶을 때!

-------------
(4) F1 score
정밀도와 재현율의 조화평균
둘 다 높아야 F1 점수가 높아짐​
 
한쪽만 높으면 F1은 낮게 나옴 (균형 중요)